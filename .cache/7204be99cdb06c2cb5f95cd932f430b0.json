{"dependencies":[{"name":"../ageGenderNet/AgeGenderNet","loc":{"line":1,"column":29}},{"name":"../faceExpressionNet/FaceExpressionNet","loc":{"line":2,"column":34}},{"name":"../faceLandmarkNet/FaceLandmark68Net","loc":{"line":3,"column":34}},{"name":"../faceLandmarkNet/FaceLandmark68TinyNet","loc":{"line":4,"column":38}},{"name":"../faceRecognitionNet/FaceRecognitionNet","loc":{"line":5,"column":35}},{"name":"../mtcnn/Mtcnn","loc":{"line":6,"column":22}},{"name":"../ssdMobilenetv1/SsdMobilenetv1","loc":{"line":7,"column":31}},{"name":"../tinyFaceDetector/TinyFaceDetector","loc":{"line":8,"column":33}},{"name":"../tinyYolov2","loc":{"line":9,"column":27}}],"generated":{"js":"\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.detectLandmarks = exports.locateFaces = exports.loadFaceDetectionModel = exports.loadAgeGenderModel = exports.loadFaceExpressionModel = exports.loadFaceRecognitionModel = exports.loadFaceLandmarkTinyModel = exports.loadFaceLandmarkModel = exports.loadTinyYolov2Model = exports.loadMtcnnModel = exports.loadTinyFaceDetectorModel = exports.loadSsdMobilenetv1Model = exports.predictAgeAndGender = exports.recognizeFaceExpressions = exports.computeFaceDescriptor = exports.detectFaceLandmarksTiny = exports.detectFaceLandmarks = exports.mtcnn = exports.tinyYolov2 = exports.tinyFaceDetector = exports.ssdMobilenetv1 = exports.nets = undefined;\n\nvar _AgeGenderNet = require(\"../ageGenderNet/AgeGenderNet\");\n\nvar _FaceExpressionNet = require(\"../faceExpressionNet/FaceExpressionNet\");\n\nvar _FaceLandmark68Net = require(\"../faceLandmarkNet/FaceLandmark68Net\");\n\nvar _FaceLandmark68TinyNet = require(\"../faceLandmarkNet/FaceLandmark68TinyNet\");\n\nvar _FaceRecognitionNet = require(\"../faceRecognitionNet/FaceRecognitionNet\");\n\nvar _Mtcnn = require(\"../mtcnn/Mtcnn\");\n\nvar _SsdMobilenetv = require(\"../ssdMobilenetv1/SsdMobilenetv1\");\n\nvar _TinyFaceDetector = require(\"../tinyFaceDetector/TinyFaceDetector\");\n\nvar _tinyYolov = require(\"../tinyYolov2\");\n\nvar nets = exports.nets = {\n  ssdMobilenetv1: new _SsdMobilenetv.SsdMobilenetv1(),\n  tinyFaceDetector: new _TinyFaceDetector.TinyFaceDetector(),\n  tinyYolov2: new _tinyYolov.TinyYolov2(),\n  mtcnn: new _Mtcnn.Mtcnn(),\n  faceLandmark68Net: new _FaceLandmark68Net.FaceLandmark68Net(),\n  faceLandmark68TinyNet: new _FaceLandmark68TinyNet.FaceLandmark68TinyNet(),\n  faceRecognitionNet: new _FaceRecognitionNet.FaceRecognitionNet(),\n  faceExpressionNet: new _FaceExpressionNet.FaceExpressionNet(),\n  ageGenderNet: new _AgeGenderNet.AgeGenderNet()\n};\n/**\r\n * Attempts to detect all faces in an image using SSD Mobilenetv1 Network.\r\n *\r\n * @param input The input image.\r\n * @param options (optional, default: see SsdMobilenetv1Options constructor for default parameters).\r\n * @returns Bounding box of each face with score.\r\n */\nvar ssdMobilenetv1 = exports.ssdMobilenetv1 = function (input, options) {\n  return nets.ssdMobilenetv1.locateFaces(input, options);\n};\n/**\r\n * Attempts to detect all faces in an image using the Tiny Face Detector.\r\n *\r\n * @param input The input image.\r\n * @param options (optional, default: see TinyFaceDetectorOptions constructor for default parameters).\r\n * @returns Bounding box of each face with score.\r\n */\nvar tinyFaceDetector = exports.tinyFaceDetector = function (input, options) {\n  return nets.tinyFaceDetector.locateFaces(input, options);\n};\n/**\r\n * Attempts to detect all faces in an image using the Tiny Yolov2 Network.\r\n *\r\n * @param input The input image.\r\n * @param options (optional, default: see TinyYolov2Options constructor for default parameters).\r\n * @returns Bounding box of each face with score.\r\n */\nvar tinyYolov2 = exports.tinyYolov2 = function (input, options) {\n  return nets.tinyYolov2.locateFaces(input, options);\n};\n/**\r\n * Attempts to detect all faces in an image and the 5 point face landmarks\r\n * of each detected face using the MTCNN Network.\r\n *\r\n * @param input The input image.\r\n * @param options (optional, default: see MtcnnOptions constructor for default parameters).\r\n * @returns Bounding box of each face with score and 5 point face landmarks.\r\n */\nvar mtcnn = exports.mtcnn = function (input, options) {\n  return nets.mtcnn.forward(input, options);\n};\n/**\r\n * Detects the 68 point face landmark positions of the face shown in an image.\r\n *\r\n * @param inputs The face image extracted from the bounding box of a face. Can\r\n * also be an array of input images, which will be batch processed.\r\n * @returns 68 point face landmarks or array thereof in case of batch input.\r\n */\nvar detectFaceLandmarks = exports.detectFaceLandmarks = function (input) {\n  return nets.faceLandmark68Net.detectLandmarks(input);\n};\n/**\r\n * Detects the 68 point face landmark positions of the face shown in an image\r\n * using a tinier version of the 68 point face landmark model, which is slightly\r\n * faster at inference, but also slightly less accurate.\r\n *\r\n * @param inputs The face image extracted from the bounding box of a face. Can\r\n * also be an array of input images, which will be batch processed.\r\n * @returns 68 point face landmarks or array thereof in case of batch input.\r\n */\nvar detectFaceLandmarksTiny = exports.detectFaceLandmarksTiny = function (input) {\n  return nets.faceLandmark68TinyNet.detectLandmarks(input);\n};\n/**\r\n * Computes a 128 entry vector (face descriptor / face embeddings) from the face shown in an image,\r\n * which uniquely represents the features of that persons face. The computed face descriptor can\r\n * be used to measure the similarity between faces, by computing the euclidean distance of two\r\n * face descriptors.\r\n *\r\n * @param inputs The face image extracted from the aligned bounding box of a face. Can\r\n * also be an array of input images, which will be batch processed.\r\n * @returns Face descriptor with 128 entries or array thereof in case of batch input.\r\n */\nvar computeFaceDescriptor = exports.computeFaceDescriptor = function (input) {\n  return nets.faceRecognitionNet.computeFaceDescriptor(input);\n};\n/**\r\n * Recognizes the facial expressions from a face image.\r\n *\r\n * @param inputs The face image extracted from the bounding box of a face. Can\r\n * also be an array of input images, which will be batch processed.\r\n * @returns Facial expressions with corresponding probabilities or array thereof in case of batch input.\r\n */\nvar recognizeFaceExpressions = exports.recognizeFaceExpressions = function (input) {\n  return nets.faceExpressionNet.predictExpressions(input);\n};\n/**\r\n * Predicts age and gender from a face image.\r\n *\r\n * @param inputs The face image extracted from the bounding box of a face. Can\r\n * also be an array of input images, which will be batch processed.\r\n * @returns Predictions with age, gender and gender probability or array thereof in case of batch input.\r\n */\nvar predictAgeAndGender = exports.predictAgeAndGender = function (input) {\n  return nets.ageGenderNet.predictAgeAndGender(input);\n};\nvar loadSsdMobilenetv1Model = exports.loadSsdMobilenetv1Model = function (url) {\n  return nets.ssdMobilenetv1.load(url);\n};\nvar loadTinyFaceDetectorModel = exports.loadTinyFaceDetectorModel = function (url) {\n  return nets.tinyFaceDetector.load(url);\n};\nvar loadMtcnnModel = exports.loadMtcnnModel = function (url) {\n  return nets.mtcnn.load(url);\n};\nvar loadTinyYolov2Model = exports.loadTinyYolov2Model = function (url) {\n  return nets.tinyYolov2.load(url);\n};\nvar loadFaceLandmarkModel = exports.loadFaceLandmarkModel = function (url) {\n  return nets.faceLandmark68Net.load(url);\n};\nvar loadFaceLandmarkTinyModel = exports.loadFaceLandmarkTinyModel = function (url) {\n  return nets.faceLandmark68TinyNet.load(url);\n};\nvar loadFaceRecognitionModel = exports.loadFaceRecognitionModel = function (url) {\n  return nets.faceRecognitionNet.load(url);\n};\nvar loadFaceExpressionModel = exports.loadFaceExpressionModel = function (url) {\n  return nets.faceExpressionNet.load(url);\n};\nvar loadAgeGenderModel = exports.loadAgeGenderModel = function (url) {\n  return nets.ageGenderNet.load(url);\n};\n// backward compatibility\nvar loadFaceDetectionModel = exports.loadFaceDetectionModel = loadSsdMobilenetv1Model;\nvar locateFaces = exports.locateFaces = ssdMobilenetv1;\nvar detectLandmarks = exports.detectLandmarks = detectFaceLandmarks;\n//# sourceMappingURL=nets.js.map"},"hash":"55c515442a8b0aab025e95759a587adf"}