{"dependencies":[{"name":"tslib","loc":{"line":1,"column":39}},{"name":"../classes/FaceDetection","loc":{"line":2,"column":30}},{"name":"../env","loc":{"line":3,"column":20}},{"name":"./createCanvas","loc":{"line":4,"column":29}},{"name":"./getContext2dOrThrow","loc":{"line":5,"column":36}},{"name":"./imageTensorToCanvas","loc":{"line":6,"column":36}},{"name":"./toNetInput","loc":{"line":7,"column":27}}],"generated":{"js":"\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.extractFaces = extractFaces;\n\nvar _tslib = require(\"tslib\");\n\nvar _FaceDetection = require(\"../classes/FaceDetection\");\n\nvar _env = require(\"../env\");\n\nvar _createCanvas = require(\"./createCanvas\");\n\nvar _getContext2dOrThrow = require(\"./getContext2dOrThrow\");\n\nvar _imageTensorToCanvas = require(\"./imageTensorToCanvas\");\n\nvar _toNetInput = require(\"./toNetInput\");\n\n/**\r\n * Extracts the image regions containing the detected faces.\r\n *\r\n * @param input The image that face detection has been performed on.\r\n * @param detections The face detection results or face bounding boxes for that image.\r\n * @returns The Canvases of the corresponding image region for each detected face.\r\n */\nfunction extractFaces(input, detections) {\n  return (0, _tslib.__awaiter)(this, void 0, void 0, function () {\n    var Canvas, canvas, netInput, tensorOrCanvas, _a, ctx, boxes;\n    return (0, _tslib.__generator)(this, function (_b) {\n      switch (_b.label) {\n        case 0:\n          Canvas = _env.env.getEnv().Canvas;\n          canvas = input;\n          if (!!(input instanceof Canvas)) return [3 /*break*/, 5];\n          return [4 /*yield*/, (0, _toNetInput.toNetInput)(input)];\n        case 1:\n          netInput = _b.sent();\n          if (netInput.batchSize > 1) {\n            throw new Error('extractFaces - batchSize > 1 not supported');\n          }\n          tensorOrCanvas = netInput.getInput(0);\n          if (!(tensorOrCanvas instanceof Canvas)) return [3 /*break*/, 2];\n          _a = tensorOrCanvas;\n          return [3 /*break*/, 4];\n        case 2:\n          return [4 /*yield*/, (0, _imageTensorToCanvas.imageTensorToCanvas)(tensorOrCanvas)];\n        case 3:\n          _a = _b.sent();\n          _b.label = 4;\n        case 4:\n          canvas = _a;\n          _b.label = 5;\n        case 5:\n          ctx = (0, _getContext2dOrThrow.getContext2dOrThrow)(canvas);\n          boxes = detections.map(function (det) {\n            return det instanceof _FaceDetection.FaceDetection ? det.forSize(canvas.width, canvas.height).box.floor() : det;\n          }).map(function (box) {\n            return box.clipAtImageBorders(canvas.width, canvas.height);\n          });\n          return [2 /*return*/, boxes.map(function (_a) {\n            var x = _a.x,\n                y = _a.y,\n                width = _a.width,\n                height = _a.height;\n            var faceImg = (0, _createCanvas.createCanvas)({ width: width, height: height });\n            (0, _getContext2dOrThrow.getContext2dOrThrow)(faceImg).putImageData(ctx.getImageData(x, y, width, height), 0, 0);\n            return faceImg;\n          })];\n      }\n    });\n  });\n}\n//# sourceMappingURL=extractFaces.js.map"},"hash":"a79c9e4ba0e4f810a13c1bea020d362a"}